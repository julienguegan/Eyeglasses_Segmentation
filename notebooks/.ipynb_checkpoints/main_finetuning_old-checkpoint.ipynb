{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import  transforms, utils\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "from bisenet import BiSeNet\n",
    "from dataset import CustomDataset, display_result\n",
    "from loss import OhemCELoss, BCELoss2d, DiceLoss, CrossEntropyLoss2d, NLLLoss2d\n",
    "from metrics import IoU_score\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from colorama import init\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(123456)\n",
    "torch.manual_seed(123456)\n",
    "torch.cuda.manual_seed(123456)\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms to the ImageFolder structure\n",
    "data_root = \"C:\\\\Users\\\\gueganj\\\\Desktop\\\\My_DataBase\\\\database_10k\\\\with_one_glasses_eyes_cropped\\\\\"\n",
    "# Models\n",
    "model_name = \"unet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 1\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Learning rate\n",
    "lr = 0.001\n",
    "# Momentum\n",
    "momentum = 0.99\n",
    "# Weight decay\n",
    "weight_decay = 0.0001\n",
    "# algorithm use for optimization\n",
    "algo_optim = 'SGD'\n",
    "# Number of epochs to train for \n",
    "num_epochs = 100\n",
    "# prediction threshold\n",
    "threshold = 0.25\n",
    "# size of image in input\n",
    "input_size = 224\n",
    "# total number of image used\n",
    "size_dataset = 10\n",
    "# Flag for feature extracting. When False, we finetune the whole model, when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "# Flag for using Tensorboard tool\n",
    "use_tensorboard = False\n",
    "# Flag for using data augmentation\n",
    "use_augmentation = False\n",
    "# Flag for using a learning rate scheduler\n",
    "lr_scheduler = \"constant\"\n",
    "# Load checkpoint\n",
    "load_checkpoint = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba6ebc1a7ee494497f61da6fe803e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatLogSlider(value=8.0, base=2.0, description='Batch Size', max=10.0, min=2.0, readout_format='d', step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0f134be0b94d99baa2f361b7176095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatLogSlider(value=0.001, description='Learning Rate', max=2.0, min=-6.0, readout_format='.1g', step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7df8220a6f24a0783f0a6791226f214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='LR scheduler', options=('Constant', 'Cosine', 'Exponential', 'Reduce On Plateau'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d7433032d543a1b64d2e7c2342a728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatLogSlider(value=128.0, base=2.0, description='Image Size', max=10.0, min=7.0, readout_format='d', step=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe9d7f16b9f40bbaf322e3926601155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='Dataset Size', max=1000, min=100, step=100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9611902a9d4309a5840a3e9b842098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='Number of Epochs', max=1000, min=10, step=10, style=SliderStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8aa96ba482468cb8492f9787fb1566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.9, description='Momentum', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a3991cb4de44e0abdd5242e6520b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Use Data Augmentation', options=('yes', 'no'), style=DescriptionStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e912f1f08ea4956b8e7138831955353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Use Tensorboard', options=('yes', 'no'), style=DescriptionStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a046925fb564e1db555c5eca1c05dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Optimizer', options=('SGD', 'Adam', 'RMSprop', 'ASGD', 'Adamax', 'Adagrad', 'Adadel…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "w1 = widgets.FloatLogSlider(value=8, base=2, min=2, max=10, step=1, description='Batch Size', readout_format='d')\n",
    "w2 = widgets.FloatLogSlider(value=0.001, base=10, min=-6, max=2, step=1, description='Learning Rate', readout_format='.1g')\n",
    "w3 = widgets.ToggleButtons(options=['Constant', 'Cosine', 'Exponential', 'Reduce On Plateau'], description='LR scheduler')\n",
    "w4 = widgets.FloatLogSlider(value=8, base=2, min=7, max=10, step=1, description='Image Size', readout_format='d')\n",
    "w5 = widgets.IntSlider(value=100, min=100, max=1000, step=100, description='Dataset Size', readout_format='d')\n",
    "w6 = widgets.IntSlider(value=100, min=10, max=1000, step=10, description='Number of Epochs', readout_format='d', style = {'description_width': 'initial'})\n",
    "w7 = widgets.FloatSlider(value=0.9, min=0, max=1, step=0.01, description='Momentum')\n",
    "w8 = widgets.RadioButtons(options=['yes', 'no'], description='Use Data Augmentation', style = {'description_width': 'initial'})\n",
    "w9 = widgets.RadioButtons(options=['yes', 'no'], description='Use Tensorboard', style = {'description_width': 'initial'})\n",
    "w0 = widgets.ToggleButtons(options=['SGD', 'Adam', 'RMSprop', 'ASGD', 'Adamax', 'Adagrad', 'Adadelta'], description='Optimizer')\n",
    "display(w1,w2,w3,w4,w5,w6,w7,w8,w9,w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and Reshape the Networks\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "if model_name == \"bisenet\":\n",
    "    # Load\n",
    "    file_path  = 'C:\\\\Users\\\\gueganj\\\\Desktop\\\\face parsing - PyTorch\\\\res\\\\cp\\\\79999_iter.pth'\n",
    "    model = BiSeNet(n_classes=19) # trained on 19 classes\n",
    "    model.load_state_dict(torch.load(file_path, map_location=device))\n",
    "    # change final layer to tune and output only 2 classes\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    model.conv_out.conv_out   = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    model.conv_out16.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    model.conv_out32.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    '''for name, param in model.ffm.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    for name, param in model.cp.conv_head16.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    for name, param in model.cp.conv_head32.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    for name, param in model.cp.resnet.layer4[1].named_parameters():\n",
    "        param.requires_grad = True'''\n",
    "elif model_name == \"unet\":\n",
    "    import segmentation_models_pytorch as smp\n",
    "    model = smp.Unet(encoder_name='mobilenet_v2', activation=None) # Activation=None because I apply activation layer myself\n",
    "    model.segmentation_head[0] = nn.Conv2d(16, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c02de2dab4cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mtest_dataset\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mask_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mtrain_loader\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mtest_loader\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# map-style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[1;32m---> 96\u001b[1;33m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# data augmentation\n",
    "transform_test = transforms.Compose([\n",
    "                    transforms.Resize((input_size, input_size)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
    "if use_augmentation:\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Resize((input_size, input_size)),\n",
    "                    transforms.RandomAffine(\n",
    "                        degrees=10,\n",
    "                        translate=(0.1, 0.1),\n",
    "                        scale=(0.9, 1.1),\n",
    "                        resample=2,\n",
    "                        shear=5),\n",
    "                    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
    "else:\n",
    "    transform_train = transform_test\n",
    "    \n",
    "# path\n",
    "folder_data = glob.glob(os.path.join(data_root,\"images\\\\*.jpg\"))\n",
    "folder_mask = glob.glob(os.path.join(data_root,\"masks\\\\*.jpg\"))\n",
    "# suffle the 2 lists the same way (to be sure)\n",
    "lists_shuffled = list(zip(folder_data, folder_mask))\n",
    "random.shuffle(lists_shuffled)\n",
    "folder_data, folder_mask = zip(*lists_shuffled)\n",
    "# split in train/test\n",
    "train_size = int(0.8 * size_dataset)\n",
    "test_size  = int(0.2 * size_dataset)\n",
    "train_image_paths = folder_data_list[:train_size]\n",
    "train_mask_paths  = folder_mask_list[:train_size]\n",
    "test_image_paths  = folder_data_list[train_size:train_size+test_size]\n",
    "test_mask_paths   = folder_mask_list[train_size:train_size+test_size]\n",
    "# create DataLoader\n",
    "train_dataset = CustomDataset(train_image_paths, train_mask_paths, transform_train)\n",
    "test_dataset  = CustomDataset(test_image_paths, test_mask_paths, transform_test)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader   = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_data[200],folder_mask[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the parameters to be optimized/updated in this run : finetuning or feature extract\n",
    "params_to_update = model.parameters()\n",
    "print(\"Parameters to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "if algo_optim == 'SGD':\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr, momentum)\n",
    "elif algo_optim == 'Adam':\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=lr)\n",
    "elif algo_optim == 'RMSprop':\n",
    "    optimizer_ft = optim.RMSprop(params_to_update, lr=lr)\n",
    "elif algo_optim == 'ASGD':\n",
    "    optimizer_ft = optim.ASGD(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adamax':\n",
    "    optimizer_ft = optim.Adamax(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adagrad':\n",
    "    optimizer_ft = optim.Adagrad(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adadelta':\n",
    "    optimizer_ft = optim.Adadelta(params_to_update, lr=lr)\n",
    "                  \n",
    "if lr_scheduler=='cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, len(train_loader))\n",
    "elif lr_scheduler=='exponential':\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=1.5)\n",
    "elif lr_scheduler=='reduceOnPlateau':\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft)\n",
    "elif lr_scheduler=='constant':\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss() #BCELoss2d() #DiceLoss() #CrossEntropyLoss2d() #DiceLoss() #NLLLoss2d\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = datetime.now().strftime(\"%d_%m_%Y-%H_%M\")\n",
    "if use_tensorboard:\n",
    "    writer    = SummaryWriter('tensorboard_logs/' + date_time)\n",
    "    # to do : configure max_queue to SummaryWriter()\n",
    "    images, labels = iter(train_loader).next()\n",
    "    img_grid = utils.make_grid(images, nrow=4, padding=10, scale_each=True)\n",
    "    lbl_grid = utils.make_grid(labels.unsqueeze(1), nrow=4, padding=10)\n",
    "    writer.add_image('Images batch', img_grid)\n",
    "    writer.add_image('Labels batch', lbl_grid)\n",
    "    writer.add_graph(model, images)\n",
    "    writer.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_checkpoint:\n",
    "    checkpoint = torch.load(load_checkpoint)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer_ft.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss  = checkpoint['loss']\n",
    "    score = checkpoint['IoU_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, criterion, num_epochs=25, threshold=0.5):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc   = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            # Iterate over data.\n",
    "            running_loss, running_iou = 0.0, 0.0\n",
    "            for i, (inputs, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # FORWARD\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    if model_name == \"bisenet\":\n",
    "                        output, out16, out32 = model(inputs)\n",
    "                    else:\n",
    "                        output = model(inputs)\n",
    "                    logits = output.squeeze(1).detach()\n",
    "                    predictions = torch.sigmoid(logits) > threshold\n",
    "                    loss = criterion(output.squeeze(1), labels)\n",
    "                    \n",
    "                    # BACKWARD (in training phase)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if lr_scheduler!=\"constant\":\n",
    "                            lr_scheduler.step()\n",
    "                        \n",
    "                # statistics\n",
    "                running_loss += loss.item() #* inputs.size(0)\n",
    "                running_iou  += IoU_score(predictions, labels)\n",
    "                if use_tensorboard and (i%int(batch_size)==0):\n",
    "                    writer.add_scalar('loss/'+phase, running_loss/(i+1), 1+i+epoch*len(dataloaders[phase]))\n",
    "                    writer.add_scalar('score/'+phase, running_iou/(i+1), 1+i+epoch*len(dataloaders[phase]))\n",
    "                    inputs_0  = inputs[0,:,:,:].permute(1,2,0)\n",
    "                    predict_0 = predictions[0,:,:]\n",
    "                    proba_0   = torch.sigmoid(logits[0,:,:])\n",
    "                    label_0   = labels[0,:,:]\n",
    "                    writer.add_figure('Result', display_result(inputs_0, label_0, predict_0, proba_0), global_step=1+i+epoch*len(dataloaders[phase]))\n",
    "                    if lr_scheduler!='constant':\n",
    "                        writer.add_scalar('lr/'+phase, lr_scheduler.get_last_lr()[0], 1+i+epoch*len(dataloaders[phase]))\n",
    "                    else:\n",
    "                        writer.add_scalar('lr/'+phase, lr, 1+i+epoch*len(dataloaders[phase]))\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_iou  = running_iou  / len(dataloaders[phase])\n",
    "\n",
    "            tqdm.write('{:5s} : Loss={:.4f} - IoU={:.4f}'.format(phase, epoch_loss, epoch_iou))\n",
    "\n",
    "                \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_iou > best_acc:\n",
    "                best_acc   = epoch_iou\n",
    "                best_model = copy.deepcopy(model)\n",
    "                ckpt_path  = 'checkpoint_logs/'+date_time+'.ckpt'\n",
    "                torch.save({'epoch':epoch,'model':best_model.state_dict(),'optimizer':optimizer.state_dict(),'loss':epoch_loss,'IoU_score':epoch_iou}, ckpt_path)\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_iou)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Accuracy: {:4f}'.format(best_acc))\n",
    "    \n",
    "    return best_model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaders dict\n",
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = train_loader\n",
    "dataloaders_dict['val']   = test_loader\n",
    "\n",
    "# Train and evaluate \n",
    "model_ft, best_acc = train_model(model, dataloaders_dict, optimizer_ft, criterion, num_epochs, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_hparams({\"Image size\":int(input_size),\n",
    "                   \"shuang/Julien\":os.path.basename(os.path.normpath(data_root)),\n",
    "                   \"Dataset size\":int(size_dataset),\n",
    "                   \"Architecture\":model_name,\n",
    "                   \"Learning rate\":lr,\n",
    "                   \"Momentum\":momentum,\n",
    "                   \"LR scheduler\": lr_scheduler.__class__.__name__ if lr_scheduler != 'constant' else 'constant',\n",
    "                   \"Optimisation algorithm\":optimizer_ft.__class__.__name__,\n",
    "                   \"Epoch number\":int(num_epochs),\n",
    "                   \"Batch size\":int(batch_size),\n",
    "                   \"Loss\":criterion.__class__.__name__,\n",
    "                   \"Threshold sigmoid\":threshold}, \n",
    "                   {'hparam/IoU score':best_acc})\n",
    "\n",
    "'''\n",
    "score_thres = 0.7\n",
    "ignore_idx  = -100\n",
    "n_min = 16 * 448 * 448//16\n",
    "LossP = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)\n",
    "Loss2 = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)\n",
    "Loss3 = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)\n",
    "#lossp, loss2, loss3 = LossP(out, labels), Loss2(out16, labels), Loss3(out32, labels)\n",
    "#loss                = lossp + loss2 + loss3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
