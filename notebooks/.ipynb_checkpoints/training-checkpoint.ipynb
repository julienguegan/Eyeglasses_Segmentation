{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gueganj\\\\Desktop\\\\Eyeglasses Detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import  transforms, utils\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "from bisenet import BiSeNet\n",
    "from dataset import CustomDataset, display_result, display_proba, Dataset_SMP, get_preprocessing, get_validation_augmentation, get_training_augmentation\n",
    "from loss import OhemCELoss, BCELoss2d, DiceLoss, CrossEntropyLoss2d, NLLLoss2d\n",
    "from metrics import IoU_score\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(123456)\n",
    "torch.manual_seed(123456)\n",
    "torch.cuda.manual_seed(123456)\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms to the ImageFolder structure\n",
    "data_root = \"C:\\\\Users\\\\gueganj\\\\Desktop\\\\My_DataBase\\\\nature\\\\\"\n",
    "# Models\n",
    "model_name = \"bisenet\"\n",
    "# encoder\n",
    "encoder = \"mobilenet_v2\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 1\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Learning rate\n",
    "lr = 0.01\n",
    "# Momentum\n",
    "momentum = 0.9\n",
    "# Weight decay\n",
    "weight_decay = 0.0001\n",
    "# algorithm use for optimization\n",
    "algo_optim = 'Adam'\n",
    "# Number of epochs to train for \n",
    "num_epochs = 100\n",
    "# prediction threshold\n",
    "threshold = 0.25\n",
    "# size of image in input\n",
    "input_size = 550\n",
    "# total number of image used\n",
    "size_dataset = 33\n",
    "# Flag for feature extracting. When False, we finetune the whole model, when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "# Flag for using Tensorboard tool\n",
    "use_tensorboard = True\n",
    "# Flag for using data augmentation\n",
    "use_augmentation = True\n",
    "# Flag for using a learning rate scheduler\n",
    "lr_scheduler = \"constant\"\n",
    "# Load checkpoint\n",
    "load_checkpoint = False #\"C:\\\\Users\\\\gueganj\\\\Desktop\\\\Eyeglasses Detection\\\\checkpoint_logs\\\\27_10_2020-11_50.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and Reshape the Networks\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "if model_name == \"bisenet\":\n",
    "    # Load\n",
    "    file_path  = 'C:\\\\Users\\\\gueganj\\\\Desktop\\\\Face_Parsing\\\\face parsing - PyTorch\\\\res\\\\cp\\\\79999_iter.pth'\n",
    "    model = BiSeNet(n_classes=19) # trained on 19 classes\n",
    "    model.load_state_dict(torch.load(file_path, map_location=device))\n",
    "    # change final layer to tune and output only 2 classes\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    model.conv_out.conv_out   = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    #model.conv_out16.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    #model.conv_out32.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    for name, param in model.ffm.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    for name, param in model.cp.conv_head16.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    for name, param in model.cp.conv_head32.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    for name, param in model.cp.resnet.layer4[1].named_parameters():\n",
    "        param.requires_grad = True\n",
    "elif model_name == \"unet\":\n",
    "    model = smp.Unet(encoder_name=encoder,  encoder_weights='imagenet', activation='sigmoid') # Activation=None because I apply activation layer myself\n",
    "    model.segmentation_head[0] = nn.Conv2d(16, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(encoder, 'imagenet')\n",
    "model.to(device)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "folder_data = glob.glob(os.path.join(data_root,\"images\\\\*.jpg\"))\n",
    "folder_mask = glob.glob(os.path.join(data_root,\"masks\\\\*.jpg\"))\n",
    "# suffle the 2 lists the same way (to be sure)\n",
    "lists_shuffled = list(zip(folder_data, folder_mask))\n",
    "random.shuffle(lists_shuffled)\n",
    "folder_data, folder_mask = zip(*lists_shuffled)\n",
    "# split in train/test\n",
    "train_size = int(0.8 * size_dataset)\n",
    "valid_size = int(0.1 * size_dataset)\n",
    "test_size  = int(0.1 * size_dataset)\n",
    "train_image_paths = folder_data[:train_size]\n",
    "train_mask_paths  = folder_mask[:train_size]\n",
    "valid_image_paths = folder_data[train_size:train_size+valid_size]\n",
    "valid_mask_paths  = folder_mask[train_size:train_size+valid_size]\n",
    "# create DataLoader\n",
    "if use_augmentation:\n",
    "    train_augmentation = get_training_augmentation(input_size,input_size)\n",
    "else:\n",
    "    train_augmentation = get_validation_augmentation(input_size,input_size)\n",
    "train_dataset = Dataset_SMP(train_image_paths, train_mask_paths, augmentation=train_augmentation, preprocessing=get_preprocessing(preprocessing_fn))\n",
    "valid_dataset = Dataset_SMP(valid_image_paths, valid_mask_paths, augmentation=get_validation_augmentation(input_size,input_size), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(image, preprocessing_fn):\n",
    "    image = image * torch.tensor(preprocessing_fn.keywords['std']).view(-1,1,1) + torch.tensor(preprocessing_fn.keywords['mean']).view(-1,1,1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters to learn:\n"
     ]
    }
   ],
   "source": [
    "# Gather the parameters to be optimized/updated in this run : finetuning or feature extract\n",
    "params_to_update = model.parameters()\n",
    "print(\"Parameters to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "\n",
    "if algo_optim == 'SGD':\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr, momentum)\n",
    "elif algo_optim == 'Adam':\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=lr)\n",
    "elif algo_optim == 'RMSprop':\n",
    "    optimizer_ft = optim.RMSprop(params_to_update, lr=lr)\n",
    "elif algo_optim == 'ASGD':\n",
    "    optimizer_ft = optim.ASGD(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adamax':\n",
    "    optimizer_ft = optim.Adamax(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adagrad':\n",
    "    optimizer_ft = optim.Adagrad(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adadelta':\n",
    "    optimizer_ft = optim.Adadelta(params_to_update, lr=lr)\n",
    "                  \n",
    "if lr_scheduler=='cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, len(train_loader))\n",
    "elif lr_scheduler=='exponential':\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=1.5)\n",
    "elif lr_scheduler=='reduceOnPlateau':\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft)\n",
    "elif lr_scheduler=='constant':\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss      = smp.utils.losses.DiceLoss()\n",
    "metrics   = [smp.utils.metrics.IoU(threshold=threshold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 550, 550]) torch.Size([8, 1, 550, 550])\n"
     ]
    }
   ],
   "source": [
    "date_time = datetime.now().strftime(\"%d_%m_%Y-%H_%M\")\n",
    "if use_tensorboard:\n",
    "    writer    = SummaryWriter('tensorboard_logs/' + date_time)\n",
    "    # to do : configure max_queue to SummaryWriter()\n",
    "    images, labels = iter(train_loader).next()\n",
    "    images = denormalize(images, preprocessing_fn)\n",
    "    print(images.shape, labels.shape)\n",
    "    img_grid = utils.make_grid(images, nrow=4, padding=10, scale_each=True)\n",
    "    lbl_grid = utils.make_grid(labels, nrow=4, padding=10)\n",
    "    writer.add_image('Images batch', img_grid)\n",
    "    writer.add_image('Labels batch', lbl_grid)\n",
    "    writer.add_graph(model, images)\n",
    "    writer.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_checkpoint:\n",
    "    checkpoint = torch.load(load_checkpoint)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer_ft.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch      = checkpoint['epoch']\n",
    "    loss_value = checkpoint['loss']\n",
    "    iou_score  = checkpoint['iou_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners, it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(model, loss=loss, metrics=metrics, optimizer=optimizer_ft, device=device, verbose=True)\n",
    "valid_epoch = smp.utils.train.ValidEpoch(model, loss=loss, metrics=metrics, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_0 = iter(valid_loader).next()[0][0,:,:,:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==================== Epoch 1/100 ====================\n",
      "train: 100%|███████████████████████████████████| 4/4 [00:37<00:00,  9.29s/it, dice_loss - 0.9841, iou_score - 0.006327]\n",
      "valid: 100%|██████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it, dice_loss - 0.9998, iou_score - 2.472e-11]\n",
      "Model saved!\n",
      "\n",
      " ==================== Epoch 2/100 ====================\n",
      "train: 100%|████████████████████████████████████| 4/4 [00:36<00:00,  9.12s/it, dice_loss - 0.9711, iou_score - 0.01632]\n",
      "valid: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.51s/it, dice_loss - 0.9911, iou_score - 0.004458]\n",
      "Model saved!\n",
      "\n",
      " ==================== Epoch 3/100 ====================\n",
      "train: 100%|█████████████████████████████████████| 4/4 [00:34<00:00,  8.55s/it, dice_loss - 0.943, iou_score - 0.02965]\n",
      "valid: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it, dice_loss - 0.9911, iou_score - 0.004458]\n",
      "\n",
      " ==================== Epoch 4/100 ====================\n",
      "train:  50%|██████████████████                  | 2/4 [00:20<00:20, 10.07s/it, dice_loss - 0.9305, iou_score - 0.03678]"
     ]
    }
   ],
   "source": [
    "# train model for 40 epochs\n",
    "best_score = 0\n",
    "for epoch in range(1, num_epochs):\n",
    "    \n",
    "    print('\\n {} Epoch {}/{} {}'.format('=' * 20, epoch, num_epochs, '=' * 20))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "    if use_tensorboard:\n",
    "        writer.add_scalar('loss/val', valid_logs['dice_loss'], epoch)\n",
    "        writer.add_scalar('score/val', valid_logs['iou_score'], epoch)\n",
    "        writer.add_scalar('loss/train', train_logs['dice_loss'], epoch)\n",
    "        writer.add_scalar('score/train', train_logs['iou_score'], epoch)\n",
    "        # do a prediction\n",
    "        with torch.no_grad():\n",
    "            prediction = model.forward(inputs_0)\n",
    "            images = denormalize(inputs_0.squeeze(0), preprocessing_fn)\n",
    "            writer.add_figure('Result', display_proba(images.permute(1,2,0), prediction.squeeze()), global_step=epoch)\n",
    "\n",
    "    # save model\n",
    "    if best_score < valid_logs['iou_score']:\n",
    "        best_score = valid_logs['iou_score']\n",
    "        best_model = copy.deepcopy(model)\n",
    "        ckpt_path  = 'checkpoint_logs/'+date_time+'.ckpt'\n",
    "        torch.save({'epoch':epoch,'model':best_model.state_dict(),'optimizer':optimizer_ft.state_dict(),'loss':valid_logs['dice_loss'],'iou_score':valid_logs['iou_score']}, ckpt_path)\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_hparams({\"Image size\":int(input_size),\n",
    "                   \"data\":os.path.basename(os.path.normpath(data_root)),\n",
    "                   \"Dataset size\":int(size_dataset),\n",
    "                   \"Architecture\":model_name,\n",
    "                   \"Learning rate\":lr,\n",
    "                   \"weight_decay\":weight_decay,\n",
    "                   \"Momentum\":momentum,\n",
    "                   \"LR scheduler\": lr_scheduler.__class__.__name__ if lr_scheduler != 'constant' else 'constant',\n",
    "                   \"Optimisation algorithm\":optimizer_ft.__class__.__name__,\n",
    "                   \"Epoch number\":int(num_epochs),\n",
    "                   \"Batch size\":int(batch_size),\n",
    "                   \"Loss\":loss.__class__.__name__,\n",
    "                   \"Threshold sigmoid\":threshold}, \n",
    "                   {'hparam/IoU score':best_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = folder_data[train_size+valid_size:train_size+valid_size+test_size]\n",
    "test_mask_paths  = folder_mask[train_size+valid_size:train_size+valid_size+test_size]\n",
    "# create DataLoader\n",
    "test_dataset = Dataset_SMP(test_image_paths, test_mask_paths, augmentation=get_validation_augmentation(input_size,input_size), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "test_epoch = smp.utils.train.ValidEpoch(model=best_model, loss=loss, metrics=metrics, device=device)\n",
    "logs       = test_epoch.run(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_SMP(train_image_paths[:10], train_mask_paths[:10], augmentation=train_augmentation, preprocessing=get_preprocessing(preprocessing_fn))\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for x,y in train_loader:\n",
    "    with torch.no_grad():\n",
    "        proba = best_model.forward(x)\n",
    "    image = denormalize(x.squeeze(0), preprocessing_fn)\n",
    "    # display\n",
    "    display_result(image.permute(1,2,0).numpy(), y, proba.squeeze(), threshold, metrics[0], display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = Dataset_SMP(valid_image_paths[:10], train_mask_paths[:10], augmentation=train_augmentation, preprocessing=get_preprocessing(preprocessing_fn))\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for x,y in test_loader:\n",
    "    with torch.no_grad():\n",
    "        proba = best_model.forward(x)\n",
    "    image = denormalize(x.squeeze(0), preprocessing_fn)\n",
    "    # display\n",
    "    display_result(image.permute(1,2,0).numpy(), y, proba.squeeze(), threshold, metrics[0], display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader  = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for x,y in test_loader:\n",
    "    with torch.no_grad():\n",
    "        proba = best_model.forward(x)\n",
    "    image = denormalize(x.squeeze(0), preprocessing_fn)\n",
    "    # display\n",
    "    display_result(image.permute(1,2,0).numpy(), y, proba.squeeze(), threshold, metrics[0], display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
