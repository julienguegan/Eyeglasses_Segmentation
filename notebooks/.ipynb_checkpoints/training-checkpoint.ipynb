{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gueganj\\\\Desktop\\\\Eyeglasses Detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import  transforms, utils\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "from models.bisenet import BiSeNet\n",
    "from dataset import Dataset_SMP, get_preprocessing, get_training_augmentation, split_data\n",
    "from display import display_result, display_proba\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(123456)\n",
    "torch.manual_seed(123456)\n",
    "torch.cuda.manual_seed(123456)\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms to the ImageFolder structure\n",
    "data_root = \"C:\\\\Users\\\\gueganj\\\\Desktop\\\\My_DataBase\\\\nature\\\\\"\n",
    "# Models\n",
    "model_name = \"unet\"\n",
    "# encoder\n",
    "encoder = \"mobilenet_v2\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 1\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Learning rate\n",
    "lr = 0.1\n",
    "# Momentum\n",
    "momentum = 0.99\n",
    "# Weight decay\n",
    "weight_decay = 0.0001\n",
    "# algorithm use for optimization\n",
    "algo_optim = 'SGD'\n",
    "# Number of epochs to train for \n",
    "num_epochs = 200\n",
    "# prediction threshold\n",
    "threshold = 0.25\n",
    "# size of image in input\n",
    "input_size = 448\n",
    "# total number of image used\n",
    "size_dataset = 33\n",
    "# Flag for feature extracting. When False, we finetune the whole model, when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "# Flag for using Tensorboard tool\n",
    "use_tensorboard = True\n",
    "# Flag for using data augmentation\n",
    "use_augmentation = True\n",
    "# Flag for using a learning rate scheduler\n",
    "lr_scheduler = \"constant\"\n",
    "# Load checkpoint\n",
    "load_checkpoint = False #\"C:\\\\Users\\\\gueganj\\\\Desktop\\\\Eyeglasses Detection\\\\checkpoint_logs\\\\27_10_2020-11_50.ckpt\"\n",
    "# Landmarks directory\n",
    "landmarks_dir = False # os.path.join(data_root,\"landmarks\",\"face_landmarks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config dictionnary\n",
    "config = {}\n",
    "for item in dir().copy():\n",
    "    if (not item.startswith('_')) and (item!='In') and (item!='Out') and item != 'config' and item != 'item':\n",
    "        if str(type(eval(item)))[8:-2] in ['str','bool','int','float']:\n",
    "            config[item] = eval(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_classes == 1:\n",
    "    activation = 'sigmoid'\n",
    "else:\n",
    "    activation = 'softmax'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Reshape the Networks\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "if model_name == \"bisenet\":\n",
    "    # Load\n",
    "    model = BiSeNet(n_classes=19) # trained on 19 classes\n",
    "    # change final layer to tune and output only 2 classes\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    model.conv_out.conv_out   = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    #model.conv_out16.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    #model.conv_out32.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    if landmarks_dir:\n",
    "        model.cp.resnet.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "elif model_name == \"unet\":\n",
    "    model = smp.Unet(encoder_name=encoder,  encoder_weights='imagenet', activation=activation)\n",
    "    model.segmentation_head[0] = nn.Conv2d(16, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    if landmarks_dir:\n",
    "        model.encoder.features[0][0] = nn.Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "elif model_name == \"DeepLabV3Plus\":\n",
    "    model = smp.DeepLabV3Plus(encoder_name=encoder,  encoder_weights='imagenet', activation=activation)\n",
    "    model.segmentation_head[0] = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(encoder, 'imagenet')\n",
    "model.to(device)\n",
    "\n",
    "print('{:,} parameters to learn'.format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "image_extension = '.jpg'\n",
    "mask_extension  = '.png'\n",
    "train_set, valid_set, test_set = split_data(data_root, \"images\", image_extension, \"masks\\\\frame\", mask_extension, size_dataset, use_id=False)\n",
    "train_image, train_mask = train_set\n",
    "valid_image, valid_mask = valid_set\n",
    "test_image, test_mask   = test_set\n",
    "# create DataLoader\n",
    "if use_augmentation:\n",
    "    train_augmentation = get_training_augmentation()\n",
    "else:\n",
    "    train_augmentation = None\n",
    "train_dataset = Dataset_SMP(train_image, train_mask, input_size, train_augmentation, get_preprocessing(preprocessing_fn), landmarks_dir)\n",
    "valid_dataset = Dataset_SMP(valid_image, valid_mask, input_size, None, get_preprocessing(preprocessing_fn), landmarks_dir)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(image, preprocessing_fn):\n",
    "    image = image * torch.tensor(preprocessing_fn.keywords['std']).view(-1,1,1) + torch.tensor(preprocessing_fn.keywords['mean']).view(-1,1,1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the parameters to be optimized/updated in this run : finetuning or feature extract\n",
    "params_to_update = model.parameters()\n",
    "print(\"Parameters to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "# Optimisation method\n",
    "if algo_optim == 'SGD':\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr, momentum)\n",
    "elif algo_optim == 'Adam':\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=lr)\n",
    "elif algo_optim == 'RMSprop':\n",
    "    optimizer_ft = optim.RMSprop(params_to_update, lr=lr)\n",
    "elif algo_optim == 'ASGD':\n",
    "    optimizer_ft = optim.ASGD(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adamax':\n",
    "    optimizer_ft = optim.Adamax(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adagrad':\n",
    "    optimizer_ft = optim.Adagrad(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adadelta':\n",
    "    optimizer_ft = optim.Adadelta(params_to_update, lr=lr)\n",
    "# LR scheduler                \n",
    "if lr_scheduler=='cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, len(train_loader))\n",
    "elif lr_scheduler=='exponential':\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=1.5)\n",
    "elif lr_scheduler=='reduceOnPlateau':\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft)\n",
    "elif lr_scheduler=='constant':\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss      = smp.utils.losses.DiceLoss()\n",
    "metrics   = [smp.utils.metrics.IoU(threshold=threshold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = datetime.now().strftime(\"%d_%m_%Y-%H_%M\")\n",
    "if use_tensorboard:\n",
    "    writer    = SummaryWriter('tensorboard_logs/' + date_time)\n",
    "    # to do : configure max_queue to SummaryWriter()\n",
    "    images, labels = iter(train_loader).next()\n",
    "    if landmarks_dir:\n",
    "        landmarks = images[:,3,:,:].unsqueeze(1)\n",
    "        images    = images[:,:3,:,:]\n",
    "        lnd_grid  = utils.make_grid(landmarks, nrow=4, padding=10)\n",
    "        writer.add_image('Landmarks batch', lnd_grid)\n",
    "\n",
    "    images   = denormalize(images, preprocessing_fn)\n",
    "    img_grid = utils.make_grid(images, nrow=4, padding=10, scale_each=True)\n",
    "    lbl_grid = utils.make_grid(labels, nrow=4, padding=10)\n",
    "    writer.add_image('Images batch', img_grid)\n",
    "    writer.add_image('Labels batch', lbl_grid)\n",
    "    writer.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_checkpoint:\n",
    "    checkpoint = torch.load(load_checkpoint, map_location=device)\n",
    "    # my own checkpoint\n",
    "    if 'model' in checkpoint.keys():\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer_ft.load_state_dict(checkpoint['optimizer'])\n",
    "        epoch      = checkpoint['epoch']\n",
    "        loss_value = checkpoint['loss']\n",
    "        iou_score  = checkpoint['iou_score']\n",
    "    # open source checkpoint\n",
    "    else: \n",
    "        model.load_state_dict(checkpoint)\n",
    "    print(\"checkpoint loaded !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners, it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(model, loss=loss, metrics=metrics, optimizer=optimizer_ft, device=device, verbose=True)\n",
    "valid_epoch = smp.utils.train.ValidEpoch(model, loss=loss, metrics=metrics, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_0 = iter(valid_loader).next()[0][0,:,:,:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 40 epochs\n",
    "best_score = 0\n",
    "for epoch in range(1, num_epochs):\n",
    "    \n",
    "    print('\\n {} Epoch {}/{} {}'.format('=' * 20, epoch, num_epochs, '=' * 20))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "    if use_tensorboard:\n",
    "        writer.add_scalar('loss/val', valid_logs['dice_loss'], epoch)\n",
    "        writer.add_scalar('score/val', valid_logs['iou_score'], epoch)\n",
    "        writer.add_scalar('loss/train', train_logs['dice_loss'], epoch)\n",
    "        writer.add_scalar('score/train', train_logs['iou_score'], epoch)\n",
    "        # do a prediction to display\n",
    "        with torch.no_grad():\n",
    "            prediction = model.forward(inputs_0)\n",
    "            if landmarks_dir:\n",
    "                inputs_0_ = inputs_0[:,:3,:,:]\n",
    "            else:\n",
    "                inputs_0_ = inputs_0[:,:3,:,:]\n",
    "            images = denormalize(inputs_0_.squeeze(0), preprocessing_fn)\n",
    "            writer.add_figure('Result', display_proba(images.permute(1,2,0), prediction), global_step=epoch)\n",
    "\n",
    "    # save model\n",
    "    if best_score < valid_logs['iou_score']:\n",
    "        best_score = valid_logs['iou_score']\n",
    "        best_model = copy.deepcopy(model)\n",
    "        ckpt_path  = 'checkpoint_logs/'+date_time+'.ckpt'\n",
    "        torch.save({'config':config,'epoch':epoch,'model':best_model.state_dict(),'optimizer':optimizer_ft.state_dict(),'loss':valid_logs['dice_loss'],'iou_score':valid_logs['iou_score']}, ckpt_path)\n",
    "        if use_tensorboard:\n",
    "            writer.add_hparams(config, {'hparam/IoU score':best_score})\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataLoader\n",
    "test_dataset = Dataset_SMP(test_image, test_mask, input_size, train_augmentation, get_preprocessing(preprocessing_fn), landmarks_dir)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "test_epoch = smp.utils.train.ValidEpoch(model=best_model, loss=loss, metrics=metrics, device=device)\n",
    "logs       = test_epoch.run(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
