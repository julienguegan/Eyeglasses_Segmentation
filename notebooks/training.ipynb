{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gueganj\\\\Desktop\\\\Eyeglasses Detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import  transforms, utils\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "from models.bisenet import BiSeNet\n",
    "from models.pranet import PraNet\n",
    "from dataset import Dataset_SMP, get_preprocessing, get_training_augmentation, split_data\n",
    "from display import display_result, display_proba\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(123456)\n",
    "torch.manual_seed(123456)\n",
    "torch.cuda.manual_seed(123456)\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms to the ImageFolder structure\n",
    "data_root = \"C:\\\\Users\\\\gueganj\\\\Desktop\\\\My_DataBase\\\\nature\\\\\"\n",
    "# Models\n",
    "model_name = \"pranet\"\n",
    "# encoder\n",
    "encoder = \"mobilenet_v2\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 1\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Learning rate\n",
    "lr = 0.1\n",
    "# Momentum\n",
    "momentum = 0.99\n",
    "# Weight decay\n",
    "weight_decay = 0.0001\n",
    "# Nesterov\n",
    "nesterov = True\n",
    "# algorithm use for optimization\n",
    "algo_optim = 'SGD'\n",
    "# Number of epochs to train for \n",
    "num_epochs = 200\n",
    "# prediction threshold\n",
    "threshold = 0.5\n",
    "# size of image in input\n",
    "input_size = [256,256] #[544,960] #[448,448] # multiple of 32 [544,960]\n",
    "# total number of image used\n",
    "size_dataset = 1000\n",
    "# Flag for feature extracting. When False, we finetune the whole model, when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "# Flag for using Tensorboard tool\n",
    "use_tensorboard = True\n",
    "# Flag for using data augmentation\n",
    "use_augmentation = True\n",
    "# Flag for using a learning rate scheduler\n",
    "lr_scheduler = \"constant\"\n",
    "# Load checkpoint\n",
    "load_checkpoint = False #\"C:\\\\Users\\\\gueganj\\\\Desktop\\\\Eyeglasses Detection\\\\checkpoint_logs\\\\27_10_2020-11_50.ckpt\"\n",
    "# Landmarks directory\n",
    "landmarks_dir = False # os.path.join(data_root,\"landmarks\",\"face_landmarks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config dictionnary\n",
    "config = {}\n",
    "for item in dir().copy():\n",
    "    if (not item.startswith('_')) and (item!='In') and (item!='Out') and item != 'config' and item != 'item':\n",
    "        if str(type(eval(item)))[8:-2] in ['str','bool','int','float']:\n",
    "            config[item] = eval(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_classes == 1:\n",
    "    activation = 'sigmoid'\n",
    "else:\n",
    "    activation = 'softmax'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32,547,319 parameters to learn\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"bisenet\":\n",
    "    # Load\n",
    "    model = BiSeNet(n_classes, activation) # trained on 19 classes\n",
    "    model.conv_out.conv_out   = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    #model.conv_out16.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    #model.conv_out32.conv_out = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    if landmarks_dir:\n",
    "        model.cp.resnet.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "elif model_name == \"unet\":\n",
    "    model = smp.Unet(encoder_name=encoder,  encoder_weights='imagenet', activation=activation)\n",
    "    model.segmentation_head[0] = nn.Conv2d(16, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    if landmarks_dir:\n",
    "        model.encoder.features[0][0] = nn.Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "elif model_name == \"DeepLabV3Plus\":\n",
    "    model = smp.DeepLabV3Plus(encoder_name=encoder,  encoder_weights='imagenet', activation=activation)\n",
    "    model.segmentation_head[0] = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "\n",
    "elif model_name == \"pranet\":\n",
    "    model = PraNet()\n",
    "    model.ra2_conv4.conv = nn.Conv2d(64, num_classes, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.ra2_conv4.bn   = nn.BatchNorm2d(num_classes, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    \n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(encoder, 'imagenet')\n",
    "model.to(device)\n",
    "\n",
    "print('{:,} parameters to learn'.format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL : 185  images -  66  personnes\n",
      "train : 145  images -  52  personnes\n",
      "valid : 15  images -  6  personnes\n",
      "test  : 25  images -  8  personnes\n"
     ]
    }
   ],
   "source": [
    "# split in train/test\n",
    "train_set, valid_set, test_set = split_data(data_root, \"images\", \".jpg\", \"masks\\\\frame\", \".png\", size_dataset, use_id=True)\n",
    "train_image, train_mask = train_set\n",
    "valid_image, valid_mask = valid_set\n",
    "test_image, test_mask   = test_set\n",
    "# augmentation\n",
    "if use_augmentation:\n",
    "    train_augmentation = get_training_augmentation()\n",
    "else:\n",
    "    train_augmentation = None\n",
    "# create DataLoader\n",
    "train_dataset = Dataset_SMP(train_image, train_mask, input_size, train_augmentation, get_preprocessing(preprocessing_fn), landmarks_dir)\n",
    "valid_dataset = Dataset_SMP(valid_image, valid_mask, input_size, None, get_preprocessing(preprocessing_fn), landmarks_dir)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(image, preprocessing_fn):\n",
    "    image = image * torch.tensor(preprocessing_fn.keywords['std']).view(-1,1,1) + torch.tensor(preprocessing_fn.keywords['mean']).view(-1,1,1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==> all 32,547,319 parameters to learn\n"
     ]
    }
   ],
   "source": [
    "n_param_total = sum(p.numel() for p in model.parameters())\n",
    "if feature_extract:\n",
    "    print(\"Parameters to learn : \")\n",
    "    params_to_update = []\n",
    "    params_to_finetuned = re.compile('(segmentation_head.*)|(decoder.blocks.[4].*.)')\n",
    "    for name, param in model.named_parameters():\n",
    "        if params_to_finetuned.match(name):\n",
    "            print(2*\"\\t\", \" - \", name)\n",
    "            params_to_update.append(param)\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "    n_param_extract = sum(p.numel() for p in params_to_update)\n",
    "    print('\\n ==> {:,}/{:,} = {:.2f} % parameters to learn'.format(n_param_extract,n_param_total,100*(n_param_extract/n_param_total)))  \n",
    "else:\n",
    "    params_to_update = model.parameters()\n",
    "    print('\\n ==> all {:,} parameters to learn'.format(n_param_total))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo_optim == 'SGD':\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr, momentum, nesterov = True)\n",
    "elif algo_optim == 'Adam':\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=lr)\n",
    "elif algo_optim == 'RMSprop':\n",
    "    optimizer_ft = optim.RMSprop(params_to_update, lr=lr)\n",
    "elif algo_optim == 'ASGD':\n",
    "    optimizer_ft = optim.ASGD(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adamax':\n",
    "    optimizer_ft = optim.Adamax(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adagrad':\n",
    "    optimizer_ft = optim.Adagrad(params_to_update, lr=lr)\n",
    "elif algo_optim == 'Adadelta':\n",
    "    optimizer_ft = optim.Adadelta(params_to_update, lr=lr)\n",
    "                  \n",
    "if lr_scheduler=='cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, len(train_loader))\n",
    "elif lr_scheduler=='exponential':\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=1.5)\n",
    "elif lr_scheduler=='reduceOnPlateau':\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft)\n",
    "elif lr_scheduler=='constant':\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight  = 20 * torch.ones((batch_size, 1, 1, 1))\n",
    "loss    = smp.utils.losses.DiceLoss() # BCEDiceLoss() # smp.utils.losses.CrossEntropyLoss() #  #  # smp.utils.losses.BCELoss(weight=weight)# \n",
    "metrics = [smp.utils.metrics.IoU(threshold=threshold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = datetime.now().strftime(\"%d_%m_%Y-%H_%M\")\n",
    "if use_tensorboard:\n",
    "    writer    = SummaryWriter('tensorboard_logs/' + date_time)\n",
    "    # to do : configure max_queue to SummaryWriter()\n",
    "    images, labels = iter(train_loader).next()\n",
    "    if landmarks_dir:\n",
    "        landmarks = images[:,3,:,:].unsqueeze(1)\n",
    "        images    = images[:,:3,:,:]\n",
    "        lnd_grid  = utils.make_grid(landmarks, nrow=4, padding=10)\n",
    "        writer.add_image('Landmarks batch', lnd_grid)\n",
    "    if len(labels.shape)==4 and labels.shape[1]==4:\n",
    "        labels = np.abs(1-labels[:,0,:,:].unsqueeze(1))\n",
    "    if len(labels.shape)==4 and labels.shape[1]==3:\n",
    "        labels = torch.sum(labels,dim=1).unsqueeze(1)\n",
    "    images   = denormalize(images, preprocessing_fn)\n",
    "    img_grid = utils.make_grid(images, nrow=4, padding=10, scale_each=True)\n",
    "    lbl_grid = utils.make_grid(labels, nrow=4, padding=10)\n",
    "    writer.add_image('Images batch', img_grid)\n",
    "    writer.add_image('Labels batch', lbl_grid)\n",
    "    writer.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_checkpoint:\n",
    "    checkpoint = torch.load(load_checkpoint, map_location=device)\n",
    "    # my own checkpoint\n",
    "    if 'model' in checkpoint.keys():\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer_ft.load_state_dict(checkpoint['optimizer'])\n",
    "        epoch      = checkpoint['epoch']\n",
    "        loss_value = checkpoint['loss']\n",
    "        iou_score  = checkpoint['iou_score']\n",
    "    # open source checkpoint\n",
    "    else: \n",
    "        model.load_state_dict(checkpoint)\n",
    "    print(\"checkpoint loaded !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners, it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(model, loss=loss, metrics=metrics, optimizer=optimizer_ft, device=device, verbose=True)\n",
    "valid_epoch = smp.utils.train.ValidEpoch(model, loss=loss, metrics=metrics, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_0 = iter(valid_loader).next()[0][0,:,:,:].unsqueeze(0)\n",
    "if landmarks_dir:\n",
    "    inputs_0 = inputs_0[:,:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==================== Epoch 1/200 ====================\n",
      "train:   0%|                                                                                    | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gueganj\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "C:\\Users\\gueganj\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:   0%|                                                                                    | 0/19 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4c0d99a4fae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n {} Epoch {}/{} {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalid_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\segmentation_models_pytorch\\utils\\train.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;31m# update loss logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\segmentation_models_pytorch\\utils\\train.py\u001b[0m in \u001b[0;36mbatch_update\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\segmentation_models_pytorch\\utils\\losses.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, y_pr, y_gt)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mignore_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         )\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_env\\lib\\site-packages\\segmentation_models_pytorch\\utils\\functional.py\u001b[0m in \u001b[0;36mf_score\u001b[1;34m(pr, gt, beta, eps, threshold, ignore_channels)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_take_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "# train model for 40 epochs\n",
    "best_score = 0\n",
    "for epoch in range(1, num_epochs):\n",
    "    \n",
    "    print('\\n {} Epoch {}/{} {}'.format('=' * 20, epoch, num_epochs, '=' * 20))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "    if use_tensorboard:\n",
    "        writer.add_scalar('loss/val', valid_logs['dice_loss'], epoch)\n",
    "        writer.add_scalar('score/val', valid_logs['iou_score'], epoch)\n",
    "        writer.add_scalar('loss/train', train_logs['dice_loss'], epoch)\n",
    "        writer.add_scalar('score/train', train_logs['iou_score'], epoch)\n",
    "        # do a prediction to display\n",
    "        with torch.no_grad():\n",
    "            prediction = model.forward(inputs_0.to(device)).cpu()\n",
    "            images = denormalize(inputs_0.squeeze(0), preprocessing_fn)\n",
    "            writer.add_figure('Result', display_proba(images.permute(1,2,0), prediction), global_step=epoch)\n",
    "\n",
    "    # save model\n",
    "    if best_score < valid_logs['iou_score']:\n",
    "        best_score = valid_logs['iou_score']\n",
    "        best_model = copy.deepcopy(model)\n",
    "        ckpt_path  = 'checkpoint_logs/'+date_time+'.ckpt'\n",
    "        torch.save({'config':config,'epoch':epoch,'model':best_model.state_dict(),'optimizer':optimizer_ft.state_dict(),'loss':valid_logs[loss.__name__],'iou_score':valid_logs['iou_score']}, ckpt_path)\n",
    "        print('Model saved!')\n",
    "        if use_tensorboard:\n",
    "            writer.add_hparams(config, {'hparam/IoU score':best_score}, run_name='config')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset_SMP(test_image, test_mask, input_size, augmentation=None, preprocessing=get_preprocessing(preprocessing_fn))\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "metrics    = [smp.utils.metrics.IoU(threshold=0.15)]\n",
    "test_epoch = smp.utils.train.ValidEpoch(model=best_model, loss=loss, metrics=metrics, device=device)\n",
    "logs       = test_epoch.run(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
