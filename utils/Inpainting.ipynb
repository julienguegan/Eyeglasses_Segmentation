{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "import albumentations as albu\n",
    "from torch import nn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image = glob.glob(\"C:\\\\Users\\\\gueganj\\\\Desktop\\\\My_DataBase\\\\nature\\\\images\\\\*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (544,960)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_inpainting(img, mask, W=10, reduce='median'):\n",
    "    new_img = img.copy()\n",
    "    Nr, Nc = img.shape[0], img.shape[1]\n",
    "    r, c = np.where(mask)\n",
    "    for i in range(len(r)):\n",
    "        bottom_left  = max(0,r[i]-W)\n",
    "        bottom_right = min(Nr,r[i]+W)\n",
    "        up_left      = max(0,c[i]-W)\n",
    "        up_right     = min(Nc,c[i]+W)\n",
    "        window_msk = mask[bottom_left:bottom_right,up_left:up_right]\n",
    "        window_img = img[bottom_left:bottom_right,up_left:up_right]\n",
    "        while len(window_img[window_msk==0]) == 0: # if there is only mask in window\n",
    "            bottom_left  = max(0,bottom_left-1)\n",
    "            bottom_right = min(Nr,bottom_right+1)\n",
    "            up_left      = max(0,up_left-1)\n",
    "            up_right     = min(Nc,up_right+1)\n",
    "            window_msk = mask[bottom_left:bottom_right,up_left:up_right]\n",
    "            window_img = img[bottom_left:bottom_right,up_left:up_right]\n",
    "        if reduce == 'median': # less sensitive to window size\n",
    "            new_pixel  = np.median(window_img[window_msk==0], axis=0)\n",
    "        elif reduce == 'mean':\n",
    "            new_pixel  = np.mean(window_img[window_msk==0], axis=0)\n",
    "        new_img[r[i],c[i]] = new_pixel\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image = glob.glob('C:\\\\Temp\\\\data\\\\video_image_4\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:\\\\Users\\\\gueganj\\\\Desktop\\\\My_DataBase\\\\nature\\\\'\n",
    "image_path = os.path.join(root,'images','021_scanRecordPD_0.jpg')\n",
    "image_name = os.path.basename(image_path)\n",
    "img  = cv2.imread(image_path)\n",
    "img  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#img  = cv2.resize(img, (input_size[1],input_size[0]))\n",
    "mask = np.array(Image.open(root + 'masks\\\\frame\\\\' + image_name.replace('.jpg','.png')).convert('P'))\n",
    "# our labellisation is too small, dilate mask\n",
    "kernel = np.ones((4,4), np.uint8)\n",
    "mask   = cv2.dilate(mask, kernel, iterations=1)\n",
    "img_inpaint = cv2.inpaint(img, mask, 10, cv2.INPAINT_TELEA) # INPAINT_NS INPAINT_TELEA\n",
    "plt.imsave('C:\\\\Users\\\\gueganj\\\\Desktop\\\\'+image_name,img_inpaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 376/376 [01:59<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "image_id = ''\n",
    "for i, image_path in enumerate(tqdm(list_image)):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    img  = cv2.imread(image_path)\n",
    "    img  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img  = cv2.resize(img, (input_size[1],input_size[0]))\n",
    "    mask = np.array(Image.open(\"C:\\\\Temp\\\\data\\\\mask_image_4\\\\\" + image_name.replace('.jpg','.png')).convert('P'))\n",
    "    # our labellisation is too small, dilate mask\n",
    "    kernel = np.ones((4,4), np.uint8)\n",
    "    mask   = cv2.dilate(mask, kernel, iterations=1)\n",
    "    img_inpaint = cv2.inpaint(img, mask, 10, cv2.INPAINT_TELEA) # INPAINT_NS INPAINT_TELEA\n",
    "    plt.imsave('C:\\\\Temp\\\\data\\\\inpainting_4\\\\'+image_name,img_inpaint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "#outdir = \"C:\\\\Temp\\\\data\\\\inpainting_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_size, deform=\"rectangular\"):\n",
    "    \"\"\"Transformation for validation set\n",
    "    input : \n",
    "        - input_size : integer for resizing maximum side\n",
    "    output :\n",
    "        - transform : albumentations object\n",
    "    \"\"\"\n",
    "    if deform==\"square\":\n",
    "        transform = albu.Resize(input_size, input_size)\n",
    "    elif deform==\"scale\":\n",
    "        transform = albu.LongestMaxSize(input_size)\n",
    "    elif deform==\"rectangular\":\n",
    "        transform = albu.Resize(input_size[0], input_size[1])\n",
    "    else:\n",
    "        print(\"deform argument unknown\")\n",
    "        \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inpainting - change color - change frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'C:\\\\Temp\\\\data\\\\change_frame_4.avi'\n",
    "image_path = 'C:\\\\Temp\\\\data\\\\video_image_4\\\\'\n",
    "inpainting_path = 'C:\\\\Temp\\\\data\\\\inpainting_4\\\\'\n",
    "mask_path = 'C:\\\\Temp\\\\data\\\\mask_image_4\\\\'\n",
    "eye_rgba   = np.array(Image.open('eyeglasses.png'))\n",
    "eye_shape  = eye_rgba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 1/376 [00:00<00:44,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▉                                                                      | 51/376 [00:05<00:36,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▍                                                          | 101/376 [00:11<00:29,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▏                                               | 151/376 [00:16<00:24,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████▊                                     | 201/376 [00:22<00:20,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████▍                          | 251/376 [00:27<00:14,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████                | 301/376 [00:33<00:09,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 351/376 [00:39<00:02,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 376/376 [00:43<00:00,  8.70it/s]\n"
     ]
    }
   ],
   "source": [
    "fourcc     = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "video      = cv2.VideoWriter(video_name, fourcc, 15, (input_size[1],input_size[0]))\n",
    "list_image = glob.glob(os.path.join(image_path,\"*.jpg\"))\n",
    "cpt = 0\n",
    "for i in tqdm(range(len(list_image))):\n",
    "    if i % 50 == 0:\n",
    "        cpt = cpt + 1\n",
    "        if (cpt % 4 == 1): print(\"original\")\n",
    "        if (cpt % 4 == 2): print(\"change color\")\n",
    "        if (cpt % 4 == 3): print(\"inpainting\")\n",
    "        if (cpt % 4 == 0): print(\"change frame\")\n",
    "    cpt = 4\n",
    "    # get mask if needed        \n",
    "    if (cpt % 4 == 2) or (cpt % 4 == 0):\n",
    "        mask_name = os.path.join(mask_path, str(i)+'.png')\n",
    "        mask = np.array(Image.open(mask_name).convert('P'))\n",
    "    \n",
    "    # read image\n",
    "    img = plt.imread(os.path.join(image_path, str(i)+'.jpg'))\n",
    "    # resize\n",
    "    img = cv2.resize(img, (input_size[1],input_size[0]))\n",
    "   \n",
    "    # inpainting\n",
    "    if (cpt % 4 == 3) or (cpt % 4 == 0):\n",
    "        img = plt.imread(os.path.join(inpainting_path,str(i)+'.jpg'))\n",
    "\n",
    "    # new color\n",
    "    if (cpt % 4 == 2):\n",
    "        img[mask==1,:] = img[mask==1,:] + [80,-20,-20]\n",
    "        \n",
    "    # new frame\n",
    "    if (cpt % 4 == 0):\n",
    "        # perspective\n",
    "        mask[400:,:] = 0 #filter\n",
    "        br,bl,ur,ul = get_box_eyeglasses(mask)\n",
    "        dst = np.float32([ul,ur,bl,br])\n",
    "        src = np.float32([[0, 0], [eye_rgba.shape[1] - 1, 0], [0, eye_rgba.shape[0] - 1], [eye_rgba.shape[1] - 1, eye_rgba.shape[0] - 1]])\n",
    "        # conserve +- heigth/width proportion\n",
    "        h1, w1 = src[2,1]-src[0,1], src[1,0]-src[0,0]\n",
    "        h2, w2 = dst[2,1]-dst[0,1], dst[1,0]-dst[0,0]\n",
    "        h      = (h1/w1)*w2\n",
    "        dst[2,1] = dst[0,1] + round(5*h/4) # work here because new eyeglasses are smaller\n",
    "        dst[3,1] = dst[1,1] + round(5*h/4) # otherwise substraction might be needed\n",
    "        dst[0,1] = dst[0,1] + round(h/4)\n",
    "        dst[1,1] = dst[1,1] + round(h/4)\n",
    "        M = cv2.getPerspectiveTransform(src,dst)\n",
    "        eye_perspective = cv2.warpPerspective(eye_rgba, M, (mask.shape[1],mask.shape[0]))\n",
    "        # merge with alpha channel\n",
    "        alpha_eyeglasses = np.expand_dims(eye_perspective[:,:,3]/255, axis=2)\n",
    "        alpha_original   = 1.0 - alpha_eyeglasses\n",
    "        img_merge = (alpha_eyeglasses * eye_perspective[:,:,:3]).astype(int) + (alpha_original * img).astype(int)\n",
    "        # get back to full image\n",
    "        img = img.copy()\n",
    "        img =  np.uint8(img_merge)\n",
    "\n",
    "    video.write(cv2.cvtColor(img,cv2.COLOR_RGB2BGR))\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective eyeglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_eyeglasses(mask):\n",
    "    # rectangle box\n",
    "    idx          = np.where(mask)\n",
    "    x_max, x_min = idx[0].max(), idx[0].min()\n",
    "    y_max, y_min = idx[1].max(), idx[1].min()\n",
    "    mask_w = mask[x_min:x_max,y_min:y_max]\n",
    "    # small parallelogram box\n",
    "    y_max_1 = int(np.min(np.where(mask[x_max,:]))) # use min ou max ou median ?\n",
    "    y_min_1 = int(np.max(np.where(mask[x_min,:])))\n",
    "    x_max_1, x_max_2 = max(np.where(mask[:,y_max_1])[0]), min(np.where(mask[:,y_max_1])[0])\n",
    "    x_min_1, x_min_2 = max(np.where(mask[:,y_min_1])[0]), min(np.where(mask[:,y_min_1])[0])\n",
    "    # final box\n",
    "    coeff  = (x_min_1-x_max_1)/(y_min_1-y_max_1)\n",
    "    offset = x_min_1-coeff*y_min_1\n",
    "    x1, x2 = round(coeff*y_max+offset), round(coeff*y_min+offset)\n",
    "    coeff  = (x_min_2-x_max_2)/(y_min_1-y_max_1)\n",
    "    offset = x_min_2-coeff*y_min_1\n",
    "    x3, x4 = round(coeff*y_max+offset), round(coeff*y_min+offset)\n",
    "\n",
    "    return (y_max,x1),(y_min,x2),(y_max,x3),(y_min,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
